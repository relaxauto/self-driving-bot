{"nbformat":4,"nbformat_minor":0,"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.6.9"},"colab":{"name":"jetbot_check_benchmark.ipynb","provenance":[]}},"cells":[{"cell_type":"markdown","metadata":{"id":"POr33Dod3zpU","colab_type":"text"},"source":["The notebook is to run in jetbot to benchmark inference speed. To be consise, the proces should include pre & post functions"]},{"cell_type":"markdown","metadata":{"id":"8yBHwmOv3lZ0","colab_type":"text"},"source":["# Import Library\n","\n"]},{"cell_type":"code","metadata":{"id":"Wh-HniaE3id9","colab_type":"code","colab":{}},"source":["# Importing the Keras libraries and packages\n","import tensorflow as tf\n","# from tensorflow.python.keras.models import Sequential\n","import tensorflow.keras\n","from tensorflow.keras.models import load_model, model_from_yaml\n","from tensorflow.keras.preprocessing.image import ImageDataGenerator\n","import IPython.display as display\n","from pathlib import Path\n","import numpy as np\n","import datetime as dt\n","from PIL import Image\n","import os, sys, cv2, random, math, pickle, time"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"BRuOHqYK3o98","colab_type":"text"},"source":["# Define Processing Functions"]},{"cell_type":"code","metadata":{"id":"P34hG7PH3ieJ","colab_type":"code","colab":{}},"source":["def convertToOneHot(left,right):\n","    if left == right:\n","        return [0,1,0]\n","    elif left > right: # Turn Right\n","        return [0,0,1]\n","    elif right > left: # Turn Left\n","        return [1,0,0]\n","\n","## This function have to deploy to jetbot\n","def preprocess(image, h=224, w=224, crop_top=0.0, color=False): \n","\n","    \"\"\"\n","    The function is to preprocess image before feeding into model. \n","    Current feature include resize image based on h and w, vertical cropping, and change color.\n","    \n","    :param image: input imag\n","    :param h: target height of output image in pixel. Default to 224\n","    :param w: target width of output image in pixel. Default to 224\n","    :param crop_top: Determine whether to crop the top part of the image. use ratio value. e.g. 0.5 mean crop top half of image. Default to 0\n","    :param color: cv2 color conversion. Put False if want to keep original color. Default to cv2.COLOR_RGB2YUV. Possible values [cv2.COLOR_BGR2GRAY,cv2.COLOR_RGB2YUV,cv2.COLOR_RGB2GRAY,cv2.COLOR_RGB2GRAY, cv2.COLOR_BGR2RGB, cv2.COLOR_RGB2BGR]\n","    :return normalized and processed image\n","    \n","    \"\"\"\n","\n","    height, _, _ = image.shape\n","    image = image[int(height*crop_top):,:,:]  # remove top half of the image, as it is not relevant for lane following\n","    if color:\n","      image = cv2.cvtColor(image, color) \n","    image = cv2.GaussianBlur(image, (3,3), 0)\n","    image = cv2.resize(image, (w,h)) # input image size (200,66) Nvidia model\n","    image = image / 255 # normalizing\n","\n","    return image\n","  \n","def process_prediction(prediction):\n","    predicted_index = np.argmax(prediction)\n","    result = np.zeros(len(prediction))\n","    result[predicted_index] = 1\n","    return result\n"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"89OoXAVz3tg4","colab_type":"text"},"source":["# Load Sample Data"]},{"cell_type":"code","metadata":{"id":"xZtd1Euc3ieP","colab_type":"code","colab":{}},"source":["## Start To Change ##\n","\n","BASE_DIR = os.getcwd()\n","EXP_MODEL_DIR = os.path.join(BASE_DIR, 'models')\n","RAW_DATA_DIR  = os.path.join(BASE_DIR,'data') ## Change Here\n","\n","## End To Change ##"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"SLOvR-Vl3ieU","colab_type":"code","colab":{},"outputId":"7ac093cb-8aaa-4868-e63e-569b7aafc79a"},"source":["data_x = [] ## Input (224)\n","data_y = [] ## Label (motor left, motor right)\n","SAMPLE_SIZE = 1000\n","## Load data from raw data folder\n","## Data is split to 2 differant arrays\n","\n","for obj in os.listdir(RAW_DATA_DIR):\n","  if obj.endswith('.npy'):\n","    data = np.load(os.path.join(RAW_DATA_DIR,obj),allow_pickle=True)\n","    data = data[((data[:,0] > 0.0) & (data[:,1] > 0.0))]\n","    print(f'Loaded : {obj} for {data.shape}' )\n","    data_x.extend(data[:SAMPLE_SIZE,2])\n","    data_y.extend(data[:SAMPLE_SIZE,0:2])\n","\n","data_x = np.array(data_x)\n","data_y = np.array(data_y)\n","print(f'All Input: {data_x.shape} \\t All Label: {data_y.shape}')"],"execution_count":0,"outputs":[{"output_type":"stream","text":["Loaded : training_data_all_2020_Feb_14_00_05_59.npy for (6330, 3)\n","All Input: (1000, 224, 224, 3) \t All Label: (1000, 2)\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"fk9gGRZS4KCA","colab_type":"text"},"source":["Define some parameters"]},{"cell_type":"code","metadata":{"id":"4zNHuzwn3iea","colab_type":"code","colab":{}},"source":["IMG_H = 66 ## Change Here\n","IMG_W = 200 ## Change Here\n","T_CROP = 0.30 ## Change Here\n","COLOR_CONV = cv2.COLOR_BGR2YUV ## Change Here"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"srNp4NPs3iee","colab_type":"text"},"source":["# HDF5"]},{"cell_type":"code","metadata":{"id":"wB4v_mo13ief","colab_type":"code","colab":{},"outputId":"07db3ceb-a678-44b0-9b0e-209a0c7e68f3"},"source":["HDF5_PATH = os.path.join(EXP_MODEL_DIR, 'Pilotnet_CAT_YUV_50E_TF114_model.h5') ## Change here\n","model = load_model(HDF5_PATH)\n","print(f\"Loaded best checkpoint from disk: {HDF5_PATH}\")"],"execution_count":0,"outputs":[{"output_type":"stream","text":["WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/init_ops.py:97: calling GlorotUniform.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.\n","Instructions for updating:\n","Call initializer instance with the dtype argument instead of passing it to the constructor\n","WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/init_ops.py:1251: calling VarianceScaling.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.\n","Instructions for updating:\n","Call initializer instance with the dtype argument instead of passing it to the constructor\n","WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/init_ops.py:97: calling Zeros.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.\n","Instructions for updating:\n","Call initializer instance with the dtype argument instead of passing it to the constructor\n","Loaded best checkpoint from disk: /home/jetbot/ITI110_Project/models/Pilotnet_CAT_YUV_50E_TF114_model.h5\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"j17PhsPN3iei","colab_type":"code","colab":{},"outputId":"03afffd8-9707-49ca-8115-bc9c26423f01"},"source":["start_time = time.time()\n","x = 1 # displays the frame rate every 1 second\n","counter = 0\n","\n","for sample in data_x:\n","  \n","  sample = preprocess(sample,IMG_H,IMG_W,T_CROP,COLOR_CONV)\n","  h, w, c = sample.shape\n","  sample = sample.reshape(1,h,w,c)\n","  output_data = process_prediction(model.predict(sample, verbose=0)[0]).astype('int32').tolist()\n","\n","  counter+=1\n","  if (time.time() - start_time) > x :\n","    print(\"FPS: \", counter / (time.time() - start_time))\n","    counter = 0\n","    \n","    start_time = time.time()"],"execution_count":0,"outputs":[{"output_type":"stream","text":["FPS:  32.665664597627746\n","FPS:  32.40672334228499\n","FPS:  33.81183152877221\n","FPS:  29.82195577749627\n","FPS:  32.087411121077025\n","FPS:  33.59468238180898\n","FPS:  32.921931854670866\n","FPS:  32.592744553258015\n","FPS:  33.11960663273103\n","FPS:  33.35612395670259\n","FPS:  32.16631327079729\n","FPS:  32.95057587006682\n","FPS:  33.363131727747415\n","FPS:  31.82929986212287\n","FPS:  31.759293512944463\n","FPS:  33.9859091053166\n","FPS:  32.59137849311414\n","FPS:  33.74914471255337\n","FPS:  33.08433857926479\n","FPS:  32.261342640449925\n","FPS:  32.04344936267091\n","FPS:  33.85640725406585\n","FPS:  33.11080179143304\n","FPS:  28.996128599163168\n","FPS:  33.70179209470492\n","FPS:  32.456680195360974\n","FPS:  32.28182381113976\n","FPS:  34.2017957728349\n","FPS:  32.20915139754389\n","FPS:  32.652063530107824\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"peyAnOm23iel","colab_type":"text"},"source":["# TFLITE"]},{"cell_type":"code","metadata":{"id":"hKXqgVWU3iem","colab_type":"code","colab":{},"outputId":"508b1fb0-2b32-486f-a222-4d9012def371"},"source":["TFLITE_PATH = os.path.join(EXP_MODEL_DIR, 'Pilotnet_CAT_YUV_50E_TF114_model.tflite') ## Change here \n","\n","# Load TFLite model and allocate tensors.\n","interpreter = tf.lite.Interpreter(model_path=TFLITE_PATH)\n","print(f'Loaded Model: {TFLITE_PATH}')\n","interpreter.allocate_tensors()\n","# Get input and output tensors.\n","input_details = interpreter.get_input_details()\n","print(input_details)\n","output_details = interpreter.get_output_details()"],"execution_count":0,"outputs":[{"output_type":"stream","text":["Loaded Model: /home/jetbot/ITI110_Project/models/Pilotnet_CAT_YUV_50E_TF114_model.tflite\n","[{'name': 'conv2d_input', 'index': 20, 'shape': array([  1,  66, 200,   3], dtype=int32), 'dtype': <class 'numpy.float32'>, 'quantization': (0.0, 0)}]\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"71bK0s1S3iep","colab_type":"code","colab":{},"outputId":"e541b1e2-7907-4511-bf0a-4363947284ce"},"source":["start_time = time.time()\n","x = 1 # displays the frame rate every 1 second\n","counter = 0\n","\n","for sample in data_x:\n","  \n","  sample = preprocess(sample,IMG_H,IMG_W,T_CROP,COLOR_CONV)\n","  h, w, c = sample.shape\n","  sample = sample.reshape(1,h,w,c)\n","  sample = np.array(sample, dtype=np.float32) ## Change dtype based on input details print out from cell above\n","  interpreter.set_tensor(input_details[0]['index'], sample)\n","  interpreter.invoke()\n","  output_data = process_prediction(interpreter.get_tensor(output_details[0]['index'])[0]).astype('int32').tolist()\n","\n","  counter+=1\n","  if (time.time() - start_time) > x :\n","    print(\"FPS: \", counter / (time.time() - start_time))\n","    counter = 0\n","    start_time = time.time()"],"execution_count":0,"outputs":[{"output_type":"stream","text":["FPS:  35.74286935628897\n","FPS:  41.651597819826414\n","FPS:  40.23764118386315\n","FPS:  44.76568559134664\n","FPS:  33.845085631856826\n","FPS:  39.59459545568363\n","FPS:  43.162649716196725\n","FPS:  38.93639179311599\n","FPS:  39.56053636765996\n","FPS:  43.712988853446234\n","FPS:  38.87827551031079\n","FPS:  39.71584491963545\n","FPS:  43.98854744581918\n","FPS:  38.93877381960385\n","FPS:  39.977553572973164\n","FPS:  40.835055468144105\n","FPS:  39.549783713063256\n","FPS:  39.746056835395116\n","FPS:  44.56259784916584\n","FPS:  40.267914403691506\n","FPS:  40.70532027605483\n","FPS:  43.61998040580546\n","FPS:  39.63582851328458\n","FPS:  41.31281303711875\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"9DIjGLcR3ies","colab_type":"code","colab":{}},"source":[""],"execution_count":0,"outputs":[]}]}