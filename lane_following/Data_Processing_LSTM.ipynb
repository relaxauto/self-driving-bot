{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "from IPython.display import display\n",
    "import cv2\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Convert to Sequence, output one file all samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ConvertToSequence(src_folder, dest_data_x, dest_data_y, sequence_size=5):\n",
    "    \n",
    "    if not os.path.exists(os.path.dirname(dest_data_x)):\n",
    "        os.makdirs(os.path.dirname(dest_data_x))\n",
    "    \n",
    "    if not os.path.exists(os.path.dirname(dest_data_y)):\n",
    "        os.makedirs(os.path.dirname(dest_data_y))\n",
    "    \n",
    "    data_x=[]\n",
    "    data_y=[]\n",
    "    for obj in os.listdir(src_folder):\n",
    "      if obj.endswith('.npy'):\n",
    "        data = np.load(os.path.join(src_folder,obj),allow_pickle=True)\n",
    "        data = data[((data[:,0] > 0.0) & (data[:,1] > 0.0))]\n",
    "        print(f'Loaded : {obj} for {data.shape}' )\n",
    "        data_x.extend(data[:,2])\n",
    "        data_y.extend(data[:,0:2])\n",
    "    \n",
    "    data_x_seq = []\n",
    "    for i in range(len(data_x) - sequence_size):\n",
    "        data_x_seq.append(data_x[i:i+sequence_size])\n",
    "    data_x = np.array(data_x_seq)\n",
    "    data_y = np.array(data_y[sequence_size:len(data_y)])\n",
    "    \n",
    "    np.save(dest_data_x,data_x)\n",
    "    np.save(dest_data_y,data_y)\n",
    "    \n",
    "    return (data_x, data_y)\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Convert to sequence, output one file per sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ConvertToSequence_Individual(src_folder, dest_folder_x, dest_folder_y, sequence_size=5):\n",
    "    \n",
    "    if not os.path.exists(dest_folder_x):\n",
    "        os.makedirs(dest_folder_x)\n",
    "    \n",
    "    if not os.path.exists(dest_folder_y):\n",
    "        os.makedirs(dest_folder_y)\n",
    "    \n",
    "    data_x=[]\n",
    "    data_y=[]\n",
    "    for obj in os.listdir(src_folder):\n",
    "      if obj.endswith('.npy'):\n",
    "        data = np.load(os.path.join(src_folder,obj),allow_pickle=True)\n",
    "        data = data[((data[:,0] > 0.0) & (data[:,1] > 0.0))]\n",
    "        print(f'Loaded : {obj} for {data.shape}' )            \n",
    "        \n",
    "        data_x.extend(data[:,2])\n",
    "        data_y.extend(data[:,0:2])\n",
    "    \n",
    "    data_x_seq = []\n",
    "    for i in range(len(data_x) - sequence_size):\n",
    "        data_x_seq.append(data_x[i:i+sequence_size])\n",
    "    data_x = np.array(data_x_seq)\n",
    "    data_y = np.array(data_y[sequence_size:len(data_y)])\n",
    "    \n",
    "    '''\n",
    "    for i in range(len(data_x)):\n",
    "        x = data_x[i]\n",
    "        y = data_y[i]\n",
    "        np.save(dest_folder_x+str(i)+'.npy', x)\n",
    "        np.save(dest_folder_y+str(i)+'.npy', y)\n",
    "    '''    \n",
    "    print(data_x.shape)\n",
    "    print(data_y.shape)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ConvertToSequence_Individual2(src_folder, dest_folder_x, dest_folder_y, sequence_size=5):\n",
    "    \n",
    "    if not os.path.exists(dest_folder_x):\n",
    "        os.makedirs(dest_folder_x)\n",
    "    \n",
    "    if not os.path.exists(dest_folder_y):\n",
    "        os.makedirs(dest_folder_y)\n",
    "    \n",
    "    data_x=[]\n",
    "    data_y=[]\n",
    "    for obj in os.listdir(src_folder):\n",
    "      if obj.endswith('.npy'):\n",
    "        data = np.load(os.path.join(src_folder,obj),allow_pickle=True)\n",
    "        data = data[((data[:,0] > 0.0) & (data[:,1] > 0.0))]\n",
    "        print(f'Loaded : {obj} for {data.shape}' )\n",
    "        \n",
    "        temp_x = []\n",
    "        temp_x.extend(data[:,2])        \n",
    "        \n",
    "        data_x_seq = []\n",
    "        for i in range(len(temp_x) - sequence_size):\n",
    "            data_x_seq.append(temp_x[i:i+sequence_size])        \n",
    "        \n",
    "        data_x.extend(data_x_seq)\n",
    "        data_y.extend(data[sequence_size:len(data),0:2])\n",
    "        \n",
    "    \n",
    "    \n",
    "    \n",
    "    data_x = np.array(data_x)\n",
    "    data_y = np.array(data_y)\n",
    "    \n",
    "    print(data_x.shape)\n",
    "    print(data_y.shape)\n",
    "    \n",
    "    \n",
    "    for i in range(len(data_x)):\n",
    "        x = data_x[i]\n",
    "        y = data_y[i]\n",
    "        np.save(dest_folder_x+str(i)+'.npy', x)\n",
    "        np.save(dest_folder_y+str(i)+'.npy', y)\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train\n",
    "\n",
    "Creating training data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "src_folder = './data_black_track/feb19/'\n",
    "dest_data_x = './data_black_track_splitted/x/x.npy'\n",
    "dest_data_y = './data_black_track_splitted/y/y.npy'\n",
    "dest_folder_x = './data_black_track_splitted/x/'\n",
    "dest_folder_y = './data_black_track_splitted/y/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "#data_x, data_y = ConvertToSequence(src_folder, dest_data_x,dest_data_y,sequence_size=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "#ConvertToSequence_Individual(src_folder=src_folder, dest_folder_x=dest_folder_x,dest_folder_y=dest_folder_y,sequence_size=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded : leecw_2020_Feb_19_07_25_28.npy for (161, 3)\n",
      "Loaded : leecw_2020_Feb_19_07_26_53.npy for (196, 3)\n",
      "Loaded : leecw_2020_Feb_19_07_27_31.npy for (298, 3)\n",
      "Loaded : leecw_2020_Feb_19_07_27_52.npy for (76, 3)\n",
      "Loaded : leecw_2020_Feb_19_07_28_10.npy for (298, 3)\n",
      "Loaded : leecw_2020_Feb_19_07_29_53.npy for (298, 3)\n",
      "Loaded : leecw_2020_Feb_19_07_31_30.npy for (194, 3)\n",
      "Loaded : leecw_2020_Feb_19_07_34_11.npy for (298, 3)\n",
      "Loaded : leecw_2020_Feb_19_07_34_29.npy for (57, 3)\n",
      "Loaded : leecw_2020_Feb_19_07_34_49.npy for (298, 3)\n",
      "Loaded : leecw_2020_Feb_19_07_35_06.npy for (51, 3)\n",
      "Loaded : leecw_2020_Feb_19_07_35_31.npy for (298, 3)\n",
      "Loaded : leecw_2020_Feb_19_07_35_48.npy for (61, 3)\n",
      "Loaded : leecw_2020_Feb_19_07_37_10.npy for (298, 3)\n",
      "Loaded : leecw_2020_Feb_19_07_37_47.npy for (159, 3)\n",
      "(2966, 5, 224, 224, 3)\n",
      "(2966, 2)\n"
     ]
    }
   ],
   "source": [
    "ConvertToSequence_Individual2(src_folder=src_folder, dest_folder_x=dest_folder_x,dest_folder_y=dest_folder_y,sequence_size=5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TEST\n",
    "\n",
    "Create testing data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "src_folder = './data_black_track/test/'\n",
    "dest_data_x = './data_black_track_splitted/test/x/test_x.npy'\n",
    "dest_data_y = './data_black_track_splitted/test/y/test_y.npy'\n",
    "dest_folder_x = './data_black_track_splitted/test/x/'\n",
    "dest_folder_y = './data_black_track_splitted/test/y/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "#data_x, data_y = ConvertToSequence(src_folder, dest_data_x,dest_data_y, 5)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded : leecw_data_2020_Feb_09_17_54_27.npy for (330, 3)\n",
      "Loaded : leecw_data_2020_Feb_09_17_56_22.npy for (446, 3)\n",
      "Loaded : leecw_data_2020_Feb_09_17_57_43.npy for (292, 3)\n",
      "Loaded : leecw_data_2020_Feb_09_17_57_54.npy for (446, 3)\n",
      "Loaded : leecw_data_2020_Feb_09_17_59_12.npy for (282, 3)\n",
      "(1771, 5, 224, 224, 3)\n",
      "(1771, 2)\n"
     ]
    }
   ],
   "source": [
    "ConvertToSequence_Individual2(src_folder=src_folder, dest_folder_x=dest_folder_x,dest_folder_y=dest_folder_y,sequence_size=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
